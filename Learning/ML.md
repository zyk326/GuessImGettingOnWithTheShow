调模型 融合
调超参数

机器学习：数据的来源 image-net百万级的图片 ，来源于搜索引擎，还有音频的数据集，Kitty 无人驾驶的数据集，评论的数据集，文档的问答对，有声读物的数据集。
学术界做机器学习数据集的办法：爬网站，采集数据
网站：paper with code，这里是代码实现的平台。
kaggle，数据集的平台。
问问别人你的数据集放在哪里。（隐私的问题）
清洗过的数据集简单了体现不出算法，原始的数据集要花时间去预处理。
数据增强，人工合成。
爬网页数据要注意版权问题。
有数据了，考虑提升数据质量，模型质量，提升标注。有一些标注用半监督，没有标注找人标注，或者用弱监督学习。把不置信的样本先拿出来，训练模型，然后再把样本放进去或许会有性能提升。
做数据标注有大量的众包公司可以做，成本是比较低的。
画线1.2美分 画圈2.4美分 精度到像素画框更贵了。
主动学习和自训练：可以先标注一些样本，训练一个模型，然后去预测样本，把最置信的样本放到标注过的样本里，再训练模型，重复这个步骤。

文本可以用Python直接读压缩文件
做数据的清理，规则的筛选，模式的筛选。
数据清理直接用有图形界面的软件，例如OpenRefine或Trifacta Wrangler
数据变形：数据清理，标注，特征工程
数字类型的数据可以normalization把数值变成合理的区间
图片数据可以剪裁，下采样，数据质量和数据大小要做一个权衡。下采样不能太狠。
视频截取片段给机器
文本用词根化（单词中共同的部分）和语法化（is，are 通通变成be）

特征工程：
SVM模型
类型向量，把少数的部分制成unknown，这也是一种独热编码[1，0，0，0，0]
图片和视频的特征是在预训练好的模型中跑，然后把输出的倒数第二层那个向量拿出来做特征。

半监督：标一些，训练模型，预测没标的，加入已标注，滚雪球。（这是一种自训练）
有钱，众包，让人标。
用规则限制。
数据的质量和数据的数量需要有一个权衡。
无监督学习，我的数据没有标号，任务也不是预测标号，主要搞分类。
强化学习，模型跟环境交互，从环境中获得一些观察点，进行学习，我做一些行为，然后环境给我一些反馈，再进行学习。例如机器人，走一步摔倒了我就觉得下一步不要走了。

监督学习的组成部分：
目标：输入与输出是什么
损失：模型训练重要的是loss，损失函数解决的是模型预测出来的值和真实值怎么算他们的差别的问题。预测值要尽量向真实值靠近。
模型：模型的目标，我要优化这个靠近目标的过程，通常需要一个目标函数。（树，线性，核方法，神经网络）
优化：最小化损失也是优化目标。

决策树，是可解释模型，可以看到这个决策是怎么一步一步做的，回归做连续的问题，分类做离散的问题。
随机森林：我从数据中随机拿一些数出来训练一颗树，重复n次。再从这些特征中随机采样一些特征列出来。
残差：预测值和真实值的差，也就是没有做好的那一块。
树模型不太需要调参。

线性模型，eg. 例如我的预测值是我的所有输入特征的加权和?偏移。（回归）
eg.数据和参数（独热）做内积?偏移得到置信（分类）
exp（x） 是把x处于负无穷到正无穷的数换成正数

小批量随机梯度下降（mini-SGD）：当我的损失（或者其他评估指标）不再变化了，就说这个模型收敛了，依塔t ηt指在t时间内的学习率。超参数包括b批量大小和学习率，这个选取有一些玄学在里面。他是一种优化机器学习参数的算法，通过优化算法优化损失函数，为了使损失函数的最小。随机指随机采样。

softmax分两步，先η，再归一。（得到概率的输出）
MLP多层感知机，他里面有全连接层，它有可学习的参数W（m*n）（m是输出向量的长度，n是输入特征的维度），b（偏移，长度是n）
隐藏层?激活函数 ＝ 有一层隐藏层的MLP多层感知机，隐藏层参数可以调，这就是所谓的调参。
比如线性模型用mlp，
h=relu（x@w1 + b1） （激活函数relu）
y=h@w2 + b2  （输出）
失去激活函数会失去隐藏层的功能，变成线性模型一样的效果。也就是说relu让整个模型变成非线性。

卷积神经网络：
一个300*300的图，有一千个类要分，如果是一个单隐藏层的mlp，隐藏层的输出大小取到10000，那么这个模型参数有90000*10000个。
全连接是对所有的输入元素中可学习的做加权和，卷积里k*k只产生一个结果，做局部计算。
卷积层的可学习参数的个数不再跟输入的大小和输出的大小相关了，只跟k有关。
pooling层池化层，汇聚层，就是计算这个窗口里面的平均值（平均汇聚）或者最大值（最大汇聚），在k的窗口里面，即使采样点发生了小于k的移动，那通过池化操作也依然能拿到这个点。
卷积神经网络（cnn）就是说把卷积层堆起来的神经网络。用卷积层来抽取图片里的空间信息。
激活层用在卷积层之后，卷积层可以被视为特殊的全连接层。

循环神经网络
用mlp把一个变长（变化）的序列表示成一个固定（某一状态唯一）长度的向量。（如hello world 变成world hello），加上过去时限含有的信息。就是在mlp加上另一个通道。
bi-rnn双向神经网络，做完形可以适用，更好地理解上下文。

cnn做图片，rnn做文本，mlp做表格数据，transformers做文本、图片

模型评估：
精度p： 预测出的正例 且 本身就是正例 / 预测出的正例
召回r： 预测出的正例 且 本身就是正例 / 本身就是正例
F1分数：2pr / （p+r） 
y_hat 是预测值
roc是一条曲线，auc是这条曲线的面积∈（0.5，1） auc大于0.5就是本身，小于0.5就会变成1-auc
二分类，多用在广告点击预测
这些评价指标通常在课程和论文中见，但在实际的应用场景中会有一些商业指标来评估模型。

在数据上做得好，不一定在实际中也做得好，比如模型显示穿蓝色衣服的人是还不上贷款的，在现实中这就不合理。
过拟合：训练做得很好，拿到新数据就不行了。过多地去看训练数据了，而不是真正地去看后面发生了什么。
欠拟合：训练误差很高，泛化误差也很高，模型没有抓住数据里的信息。
低复杂度的模型不能很好拟合数据（欠拟合）。高复杂度的模型容易过拟合。
超参数：神经网络我的层有多少，多少宽（隐藏层的大小），要不要加正则项来限制可学习参数的范围，树有多少颗树，每颗树有多深。
我们关注模型的泛化能力，模型复杂度：模型拟合的函数多则模型复杂度高，反之低。数据复杂度：数据里有多少信息，信息量越多数据复杂度越高，反之越低。

测试数据集只能用一次。验证数据集可以使用多次，通常从训练数据集中拿出来一块。
我的验证数据集一定要在训练数据之后。
挑数据的方法也有随机，组内比例抽取，组内等量抽取等方法。
我的模型不能让训练数据拟合得太好，不然会过度关注数据细节（噪音），导致模型泛化能力降低。
验证集里出现过训练集里的内容就会出现误差，过高地估计模型的好坏。

统计里衡量模型的两个重要指标。偏差（bias）and方差（variance）
bias：训练出来的点和真实值中间的位移。
variance：每次学习的东西之间，它们的差别多大。
期望：想要的是，在不同的采样样本之间，我得到的这个值（期望）都不会很大。E[(y-f_hat)^2]
样本D={(x1,y1)......(xn,yn)}  y_true = f(x) + ε（噪音）
x是特征，y是标号

偏差过大说明模型的复杂度不够，方差过大说明模型的复杂度过高，也可以提升数据质量。
统计学里可以把泛化误差分解，泛化误差=偏差^2 + 方差 + 数据和采集模型的误差。

bagging：做训练的时候独立（并行）训练n个模型。对结果平均或类别最多选择。
方差较大：模型不稳定。
bagging主要为了降低方差，尤其是模型不稳定的时候效果最佳。

boosting：把多个比较弱的模型组合成一个比较强的模型。主要为了降低偏差。它按顺序学习n个模型。
过程：先训练一个模型，把训练好的数据拿出来，专注那些不好的数据，再训练。
用比较弱的模型去拟合我的残差。

stacking和bagging很像，它把多个base learner放在一起，用来降低方差。比如不同模型在同样的数据上训练，回归问题每个模型输出一个标量，得到长为n的向量作为输出，在加一个全连接层，得到最终输出。
炼丹方法：第一层用a训练，把第一层对b预测结果加上b本身用作第二层模型的训练。
k折交叉验证，每次在k-1上训练，验证k。
第i块数据在第i个模型上验证，在其他块上做训练。
多层的stacking，每一层在下一层的基础上更好地拟合数据。降低方差，但是容易过拟合。
还有一个k折多层stacking，在竞赛中经常使用。

调参 是很花时间的
从一个好的基线开始。每次就改一个值。有的超参数稳定，有的敏感。
调参要做笔记。
代码要放在一个地方。
注意换一个随机种子结果浮动比较大的问题。

调参数：
grid search：把所有的超参数的排列组合都试一遍，挑一组会好的出来。
random search（最常用）：最多试n次，每次随机拿一个config，拿最好的一个config出来。
贝叶斯优化：学一个从超参数到评估指标中间的那个函数。
successive halving：每次仅选最好的一半继续训练一倍长的epoch。
强者恒强：直接拿别人的超参数来用。

挑模型就看你模型的效果和跑模型的开销。

深度神经网络是一个编程语言，去表达对数据（结构上，理念上）的一些理解。深度神经网络里面的值可以一开始不用定（是可以学的一些权重），这些值根据真实的数据再得到。（先定义一个模板，模板里面的内容可以之后再学习得到）。学习通过《可导》，最后定义一个损失函数，给数据之后通过误差反转传递来进行权重更新。所以深度神经网络有很多的设计模式。

（批量和层）的归一化：
使用批量归一化之后模型可以使用更大的学习率。
批量归一化会更加平滑：（数据标准化）从x走到y，我的损失函数导数变化的平方是可以被上限bind住（表现为一个常数β乘以距离差的平方）。也就是说梯度改变的方向可以被上限bind住。β小，步长大，学习率大。（在cnn里用的多）（能去掉是最好的了）
二维是mlp输入，四维是卷积层的输入。
层的归一化用在循环神经网络和transformer里面。如果均值方差抖动比较大，那就失去了做好标准化的意义了。
（区别就是按哪个维度算均值和方差）层的归一化把参数四维变二维（reshape input），比如n c w h to cwh n
+normalization+

迁移模型的出发点：
1，在一个任务上学习的模型可以用来解决一个别的相关的任务。
2，（出圈在深度学习）原因是搞深度学习贵了。

途径：
训练好一个模型，把它做成一个专门特征抽取的模块。
训练好一个模型，在另一个任务上直接用它。
训练好一个模型，在另一个任务上对模型做一些微调。

微调固定一些层的做法是很好的。微调加速了收敛，微调让你初始的点不再是随机的点，而是处在更加接近目标的地方。越靠近最终点，整个损失就越平滑，训练就越简单。
fine-tuning用在nlp上（自然语言处理）
通常只需要改最后一层就可以了。
