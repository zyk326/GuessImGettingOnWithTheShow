# Yolo项目-垒石石墨卷

## 前置内容
pycharm，anoconda，git  

### nvidia环境配置  

nvidia-smi (查看GPU)(linux)  
```
@echo off
:loop
cls
nvidia-smi
timeout /t 1 >nul
goto loop
```
^←windows，bat文件内容  

### 实施步骤  
1. 数据集分割  
2. git下载yolov12，安装torch以及依赖包  

## 你的训练日志位置：  
主要日志目录：**runs/detect/train12/**  
训练结果：**runs/detect/train12/results.csv** - 包含每个epoch的详细指标  
模型权重：**runs/detect/train12/weights/** - 包含 best.pt 和 last.pt  
训练参数：**runs/detect/train12/args.yaml** - 记录所有训练配置  
查看 **runs/detect/train12/weights/best.pt** 获取当前最佳模型。    
在**ultralytics/cfg**里找要训练的模型的对应的网络yaml。  



## 部署的前置要求  
1. pt转ort转trt(他们的关系，含义，转换方法)  
2. 安CUDA  **C:\Users\Administrator\AppData\Local\Temp\cuda**   
3. 安cudnn 
4. 使用训练脚本训练模型，拿官方的直接转ort，使用trtexec来ort转换trt  
5. 使用trtexec需要TensorRT，到官网安装  
6. 编onnxruntime库，用c++   
7. 需要知道模型部署时，模型的训练方式是seg还是det    
8. visual studio需要修改VC++目录和链接器中的输入    

##  试运行总结
1. 在visual studio里配置库的链接  

```
包含放包含，库放库（路径）

在链接器里放对应的lib
opencv_world460.lib
onnxruntime.lib
```

2. cuda和cudnn的版本要匹配，如果出现内存错误的问题，看控制台，大概率是版本没有匹配，少部分是资源声明（释放）顺序除了问题。  

3. 编写代码要用**PImpl**设计模式。  

## 打包DLL
1. 添加宏，添加include，添加lib，添加链接器中输入的附加依赖项。  

#ifdef YOLOV11SEG_EXPORTS  
#define YOLO_API __declspec(dllexport)  
#else  
#define YOLO_API __declspec(dllexport)  

在类前加class YOLO_API YOLOV11Seg{}  

生成即可。  

在使用目前已有的feature工程时，要注意更改include路径，lib路径和生成路径。  

2. 在使用dll的时候，要添加链接器，包括  
常规：添加库目录（lib path）  
输入：附加依赖项（.lib）   
也就是说，lib是一个函数内容的索引，dll是一个包含函数内容的文件。  
lib可以放在别处，用添加库目录和依赖项的方式找到它，而dll最好是放在exe同路径下。    

# 训练曲线说明  

## 看两张图  
### F1-Confidence  
置信控制过杀，漏检。    
置信降低，过杀控制不住。  
置信升高，漏检控制不住。  

### Instance  
看缺陷的分布情况，数据平衡。   

# BOHR DFM设计文档  

## 划分模型秘籍  
主要看检测区域设计部分，在那里有主要的检测内容，包括以下内容：  
- 光源信息  
- 拍照点  
- 拍照图片数量  
- 产品移动数量  
- 拍照+存储耗时  
- Station condition的详细说明  

使用多个station的信息，来判断模型合并的可能性。  
一看光源，光源一样，那么成像就有一致的可能性。  
二看检测类型，缺陷类型一样，且光源一样，那么就有缺陷成像一致的可能性；如果光源不一样而缺陷类型一样，成像一致性不能保证，一定不能合并。    
三看图片尺寸（很有说法），图片尺寸接近有合并的可能性。   
**总的来说是看缺陷成像特征一致性**。  

使用DFM的标定最小NG尺寸来计算图片中的缺陷区域大小，使用每个图片的单像素精度计算缺陷像素块个数，使用缺陷像素块计算缩放后像素块个数，缩放后像素块不能低于9个。   

划分模型更像是一个工程定量的过程，是接下来的模型训练的总体方针，为待处理数据划定不同的处理方式，细化处理过程，落定到每个资源上。所以划分讲究合理性，资源承接性，任务量充实性，训练可行性。  

# 模型检出结果分析及措施秘籍  

## 一个好模型必须注意的三点  

1. 数据质量。  
2. 缺陷明确定义。  
3. 缺陷数量分布均衡。   

## 处理过杀漏检的部分情况及方法  

### 缺失部件情况  
可以使用特征连接来检测缺失区域，后使用分类模型来判定是否有缺失。    
两个模型串行运行。  
1. 标注部位 → 检测模型输出位置；  
2. 裁剪ROI → 分类模型判断缺料与否；  
3. 推理时串行运行两个模型，得到最终缺料检测结果。  

### 特征重叠误检情况  
将误检部位打上标注，进入模型训练，并不检测这一缺陷。  
显示负样本建模，backbone学到两者的特增差异，分类头head就能区分它们。  
让模型主动学会它长什么样。   

### 特征丢失时为缺陷情况  
将有特征时（即ok品）打上标注，未检测到即为出现缺陷。  
核心是把“存在的特征”作为正样本去检测/分割/定位，需要把模型调成“少漏报”为首要目标。  

| 检测逻辑        | 核心思路                | 典型应用        |
| ----------- | ------------------- | ----------- |
| **缺陷直接检测**  | 直接标注缺陷区域，用检测/分割模型识别 | 划痕、裂纹、缺料、异物 |
| **特征存在检测**  | 标注应存在的特征，缺失即缺陷      | 螺丝、焊点、孔位检测  |
| **负样本抑制检测** | 显式标注易误检区域为另一类，推理时忽略 | 金属反光、油污斑点误检 |
| **二阶段检测**   | 阶段1找候选 → 阶段2分类确认    | 缺料、轻微划伤     |
| **模板对比**    | 与标准模板做对齐/差分         | PCB线路、印刷缺陷  |
| **区域屏蔽**    | 检测前直接屏蔽无关区域         | 背景杂乱场景      |
| **轮廓/尺寸测量** | 基于边缘/拟合测尺寸          | 工件变形、尺寸偏差   |
| **光学对比检测**  | 用多光源拍摄，检测反射/吸收差异    | 刻字检测、反光涂层缺陷 |
| **规则阈值检测**  | 灰度、颜色、纹理特征阈值判断      | 简单表面污染      |  

## 最终要达到的    
**看到一个缺陷就要知道它的处理方式**。   

总结在一个漏检、过杀的数据集中，存在的主要缺陷有以下：  
1. 缺陷形态不一导致漏检，如本身形态多样的现状不良。  
2. 缺陷未准确定义，如压印的形态多变，点状可以是，现状也可以是。  
3. 诡异的叠放情况。  
4. 自身形态的缺失，不可控的随机的缺失。  
5. 特征消失是缺陷，这种过杀是对ok的漏检。   

直接说明：  
多的部分（废料残留）可以直接标。  
卷边折角也可以直接标。   

特征缺失型缺陷的核心是结构完整性，即对比结构是否完整。  
形态异常型缺陷是可以直接标注的，因为它们是正品中根本不存在的形态，只要出现就高度可疑。   

# 完成一个项目  
## 前期应该做的工作  
- 模型训练框架  
需要确定能够正确运行，做一个模版训练框架压缩包出来，用于各个硬件环境一键移植（因为会用到多个服务器）。    
可以确定的是yolov5在中小型模型训练中，在工业检测场景下，使用同样的数据集，同样的训练参数，性能优于yolov8。

- 数据增强工程  
需要确定数据能够正确增强，这个是工具工程，重点在正确使用，**data_conversion_utils**里的数据格式转换，标签数量统计，数据增强工具。  

## 产出评估报告  
在光学给出评估报告后，算法需要产出评估报告。  
可以结合DFM（可以是ppt形式，可以是pdf格式，重要的是看里面的缺陷图），也可以不用DFM（那就会少一批缺陷图，也可能不缺，看光学怎么发检测图，DFM只是一个补充），来评估遇到的各个缺陷类型。  
- 评估重点是认清一个缺陷的特征，以及对它的检测方法（AI或者说需要传统介入），确定AI检的自己评估并给出三级标准（风险：Low Mid High），确定需要传统介入的，叫来传统算法工程师，问问他们的意见后，确定风险标准，以上所有确定Mid High风险需要给出对应风险的理由放在备注里。    

- 评估报告可能会有多个部门磋商，自己给出的意见需要有立足点。  

## 总览表格的制作  
- 放一个智能表格在项目进度表中（自己做一个overview模版放在企业微信的智能表格里）      

- 主要是我这里算法出表格框架，使用模型的划分来确定表格结构，各项指标沿用历史指标。    
框架划分完成，交给光学及其他部门填充对应内容。  
所以，**划分模型是基本功**，需要多练。  

- 划分模型，没什么技巧，合理就行，图片数量，检测类型，不多不少得放到一个模型里检测就可以。   

- 无法确定一个缺陷用什么方式来检出，就要查看光学报告，去找光学的工程师要。  



## Airports图片查看    
**主要看轻微缺陷**。大部分都是缺少轻微缺陷的图，存在漏检风险。  
只有反面压伤缺陷特征明显，比较容易检测。  
顶面大小边可以用传统来检测。  

PVD前后的图片以及缺陷成像不一样，缺陷类型有差别，需要分别判断。  

若将缺陷标注为无成像，可能是图像中没有可用的有效图像信息。   

若是缺陷与表面相似，那就是有过杀风险。  

总结下来就是，以成像效果、混淆可能性和特征显式表达为标准来划定检测风险。  

这指导了模型划分、训练以及后期模型迭代方向。  

## 确定工控机
使用划分的模型以及工位信息，来确定工控机的承载，即哪些模型放到主机，哪些模型放到副机，来得到主副机的配置情况。  

目前的点是图片量均衡，所分配的机器模型量均衡。  

## 模型训练部分  
发来图片数据之后，他们的原始数据存放结构对于标注组来说是不方便的，可以使用脚本给他们转一下，转成以模型划分文件夹存放的形式，再给标注组标注。  

使用工具进行数据增强，不要用训练工程里的**data_conversion_utils**，它是原始版本，没有项目适配化修改。  
要用外置的数据转换工具。  

### 模型训练模版工程说明：   
- 产生训练模型对应的训练py文件。  
- 修改预训练权重。  
- 修改数据对应的yaml文件（主要是里面的缺陷类型和缺陷数量以及训练测试文件路径）。  
- 修改数据对应的txt标签（主要是缺陷名称，跟数据增强部分的名称保持一致）。  

## Alpha Vision  
模型不能有中文路径。  
模型转换参数要与训练参数对应。（主要是imagesize）   
步骤是先选算子，（yolov5是分割1 1），再加载模型，在选入图片路径。（这样可以确保不出事）  

# 吉安·立讯  
在245上（全部）249上（F2）

现在标注的都在ABDF面。  

D面的胶偏位缺陷。  
- 对于多个面的处理需要有不同的处理方式吗？  
- 对于偏位的尺寸标准是什么？  
- 明确的传统+深度学习方法检测。  
- 深度学习：打标，数据均衡，模型训练。    

胶偏的突出特点是物体包装薄膜贴合错位，导致产品两侧有薄膜突出，以及对应的薄膜未覆盖区域。  
在生产报表中，膜偏位的过杀较多。  

可以找的点：  

- 如何防过杀。  

目前训练的模型参数：  
**imagesize:1088*1088**  
训练数据直接使用**复制**来增强数据量。  
划分数据的时候，给了划分测试集的选项，获得的图片比例是0.111:1，选择划分比例的时候是1:9。   



# 东莞·领益B25 Iphone pro卡针  

1. 看评估报告。（了解有哪些缺陷）  
2. 看数据。（仔细看缺陷特征）   

具有新增缺陷，是G面。  
- 以往数据要重新做，加入新标签。（历史数据不用管）  
- 训练数据在哪里？模型训练在哪里？（找不到训练数据）（.200）  
- 数据标注是只有G面要标吗？（对的）    
- 上传的数据在哪个地方？（不知道）（.200）  

### 历史模分析  
侧面撕裂带与曲线反应相当，18,24模型检出效果差别不大。  
冲压痕的检出效果比较差，甚至24要差于18。  
脏污效果相近，24偶发性能优越与18。  
边缘缺口相差不大。  
**结论是使用24的预训练模型，但是冲压痕这部分数据试着增强一下，补充一下增强效果**。   

# Hinge  
在249上。  
一个问题：  
**后处理软件里面的那些前景背景值没显示出来**  
解决办法：更换AlphaVision（后处理软件）的四个文件（dll，lib，db啥，xxx）    


